---
title: "Data description"
output: html_document
bibliography: references.bib
---

THIS IS THE LAST ONE


vedba y odba son solo distintas formas de sumar los ejes de los acelerometros\ 
pitch y roll son derivados de acelerom y magnetom. 

walk eating, resting, fast walk, main behaviours to classify

TO DO:

-   Describe behaviours and make explicit how you end up grouping them. (e.g., eating vs eating up? vigilance vs vigilance down? if up and down mean standing or laying down, vigilance makes sense but eating doesn't). ASK
-   files named 'bis'?? ASK

-   Find out why some .csv (`raw_dic[c(31,35,37)]`) have `Pitch angle` and `Pitch.angle` vars, same with `Roll angle` and `Roll.angle`. Maybe plot them to see how they differ? maybe read the manual? 

HAVE IN MIND:

-   clean_data\$sheep_name %\>% unique %\>% length is not the same as.

    clean_data\$sheep_number %\>% unique %\>% length, because of this "bis" files. We'll use sheep_number to select individuals for now.

Notes for reader:

-   Git

    -   Cloned (downloaded) the repo from github by running `git clone https://github.com/franfram/AAR-DL.git` in your terminal (for that, ensure you first have Git installed)

<!-- -->

-   Working directory

    -   Ensure you opened the Rproject

-   Docker

    -   Docker instructions (MAYBE A docker-readme file? .rmd or .md?)

-   Renv

    -   Ensure you run renv::init() and chooe option 1: Restore the project from the lockfile.

-   Targets

```{=html}
<!-- -->
```
    -   You can inspect the results available (i.e., the 'targets' available) by running targets::tar_manifest() and then running targets::tar_read(TARGET_NAME).

    -   If you want to check

Options setup

```{r}
options(tidyverse.quiet = TRUE)
```

Chunk setup

```{r}

knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  include = TRUE,
  eval = TRUE,
  cols.print = 7,
  rows.print = 7
)

```

Library setup

```{r setup}
library(workflowr) 
library(tidyverse)
library(fs)
library(here)
library(lubridate)
library(reactable)
#library(paint)
library(hms)
library(glue)
```

Conflicted setup

```{r}
library(conflicted)

conflict_prefer("filter", "dplyr")
conflict_prefer("year", "lubridate")
```

Data came as .csv files. The original repo had two folders for data: "sep" and\
"dic", not sure why nor which files where on each folder (may be able to know\
this later). We'll suppousse those files starting with "sep" where those on the\
"sep" folder and those starting with "video" where those on the "dic" folder.\
(and that's how I organized the files on this repo).

Update: From the original paper where the data came from [@ruiz-suarez2022], we can see that "sep" means "September" and "dic" means "December".

"After discarding the videos that had not captured sheep or those for which\
acceleration data was not available, a total of 18 videos from eight different\
animals were obtained from the session of September and a total of 49 videos\
from 17 different animals from the session of December."

Files are named indicating number of video (e.g., 'video10' for the 10th video) and sheep number (e.g. ov18 for the 18th sheep)

```{r list files}
## get paths of files
sep_paths <- dir_ls(path = here("data", "sep"), glob = "*.csv") %>% 
  print()
dic_paths <- dir_ls(path = here("data", "dec"), glob = "*.csv") %>% 
  print()

```




 






September files all contain the same amount of columns (27).

```{r raw data vars, message=FALSE, warning=FALSE}

raw_sep <- sep_paths %>% 
  map(
    read_csv, 
    id = "file_name_original",
    col_types = cols()
  ) %>% 
  suppressMessages

map(raw_sep, ncol) %>% 
  unique()








```

And the column names are

```{r}
raw_sep[[1]] %>% 
  colnames 


```

Whereas December files have different amount of cols
```{r}
raw_dic <- dic_paths %>% 
  map(
    read_csv,
    id = "file_name_original",
    col_types = cols()
  ) %>% 
  suppressMessages

map(raw_dic, ncol) %>% 
  unique()

map_dfc(raw_dic, ncol) %>% 
  pivot_longer(
    everything(),
    names_to = "file_name_original",
    values_to = "ncol"
  )



```


























```{r} 


ncol(raw_dic[[37]])



```

which seems to be due to some files lacking some variables (those with less than 27 columns), but there's a particular file having 28 columns (video2_ov9).

```{r}


dic_paths[[37]]
ncol(raw_dic[[37]])
colnames(raw_dic[[37]])
```

This file seems to have 2 different Pitch angle vars with different values.




Now we will check which dataframes contain the "Pitch angle" and "Roll angle" variables (and its variants such as the smoothed ones). 
Note that all dataframes contain the `Pitch` and `Roll` variables, but most of the december dataframes lack the smoothed version of the variables. We can also see that most december and septermber dataframes contain the magnetometer variables (there's only 1 dataframe
with missing `mag` vars). Given this insights, we will keep all the `Mag` vars but only the un-smoothed `Pitch` and `Roll` vars. 
```{r}
december_vars1 <- map(raw_dic, ~ grep("(Pit|Roll|pit|roll)", names(.), value = TRUE))
september_vars1 <- map(raw_sep, ~ grep("(Pit|Roll|pit|roll)", names(.), value = TRUE))


december_vars1
unique(unlist(december_vars1))
september_vars1
unique(unlist(september_vars1))


december_vars2 <- map(raw_dic, ~ grep("(Mag|mag)", names(.), value = TRUE))
september_vars2 <- map(raw_sep, ~ grep("(Mag|mag)", names(.), value = TRUE))


december_vars2
unique(unlist(december_vars2))

september_vars2
unique(unlist(september_vars2))





```






On top of selecting the variables that we are interested in, we will also modify the date-time variables and add a few other useful ones:

-   sheep name (e.g., ov18)

-   sheep number (e.g., 18)

-   video name (e.g., video 21)

-   video number (e.g., 21)

We will also keep `Event.no.` column. This seems to be something recorded by\
the Daily Diaries that indicates the record. This column will be useful since we\
will want to make sure we have the right ordering of rows inside each second\
(remember these Daily Diaries makes 40 records per second, 40Hz).

(During the first iteration, we won't use magnetometer data. Which will allow us to avoid wrangling problems due to many December files missing magnetometer data).

```{r}
colnames(raw_sep[[1]])
```

Clean data
pitch angle is derived from magnetometer and accelerometer



```{r}
vars_to_keep <- c(
  'file_name_original',
  'Acc_x',
  'Acc_y',
  'Acc_z', 
  'Mag_x',
  'Mag_y',
  'Mag_z',
  'DateTime', 
  'Hours',
  'Minutes',
  'Seconds',
  'Event.no.',
  'Behaviours'
)


# select_vars <- function(df) {
#   select(
#     df, 
#     starts_with("Pitch"),
#     starts_with("Roll"), 
#     'file_name_original',
#     'Acc_x',
#     'Acc_y',
#     'Acc_z', 
#     'Mag_x',
#     'Mag_y',
#     'Mag_z',
#     'DateTime', 
#     'Hours',
#     'Minutes',
#     'Seconds',
#     'Event.no.',
#     'Behaviours'
#   )
# }


# A function to select the appropriate columns if they exist
select_vars <- function(df) {
  #' This function checks which of the desired columns exist in each dataframe and selects only those. The
  #' intersect function is used to identify the common columns between your desired columns and the actual
  #' columns in each dataframe. Then it combines these with the 'Pitch' and 'Roll' columns identified by 
  #' pattern matching. The all_of function is used within select to avoid errors when trying to select
  #'  non-existent columns.
  
  cols_to_select <- c(
    'file_name_original',
    'Acc_x',
    'Acc_y',
    'Acc_z', 
    'Mag_x',
    'Mag_y',
    'Mag_z',
    'DateTime', 
    'Hours',
    'Minutes',
    'Seconds',
    'Event.no.',
    'Behaviours'
  )
  
  existing_cols <- intersect(cols_to_select, names(df))
  pitch_roll_cols <- grep("Pitch|Roll", names(df), value = TRUE)
  
  select(df, all_of(c(existing_cols, pitch_roll_cols)))
}



standardize_colnames <- function(df) {
  colnames(df) <- gsub(" ", ".", colnames(df))
  return(df)
}







raw_data_dic <- dic_paths %>% 
  # Read files
  map(
    read_csv, 
    id = "file_name_original",
    col_types = cols()
  ) %>%
  # standardize colnames
  map(standardize_colnames) %>% 
  # Select vars
  map(select_vars) %>% 
  #Add sheep name column
  map(
    ~ {
      try(add_column(
        .x,
        sheep_name = str_extract(
          .x$file_name_original,
          "ov.."
        )
    ), silent = TRUE)
    }
  ) %>% 
  # Add sheep number column
  map(
    ~ try(add_column(
        .x,
        sheep_number = as.double(
          str_extract(
            .x$sheep_name,
            "[0-9]+"
          )
        )
    ), silent = TRUE)
  ) %>%
  # Add Year variable
  map(
    ~ try(mutate(
        .x,
        year = year(DateTime)
    ), silent = TRUE)
  ) %>%
  # Add Month variable
  map(
    ~ try(mutate(
        .x,
        month = month(DateTime)
    ), silent = TRUE)
  ) %>%
  # Add Day variable
  map(
    ~ try(mutate(
        .x,
        day = day(DateTime)
    ), silent = TRUE)
  ) %>%
  
  #Remove DateTime var
  map(
    ~ {
      try(select(
        .x,
        -'DateTime'
    ), silent = TRUE)

    }
  ) %>%
  # Rename all vars to lower-case names to avoid problems
  map(
    ~ {
      try(rename_all(
        .x,
        tolower
    ), silent = TRUE)

    }

  ) %>%
  # Coerce to consistent classes
  map(
    {
    ~ try(mutate_at(
        .x,
        c('hours', 'minutes', 'seconds'),
        as.double
      ), silent = TRUE)

    }
  ) %>%
  # Add column indicating video name
  map(
    ~ {try(mutate(
        .x,
        video_name = str_extract(
          .x$file_name_original,
          pattern = "video.."
        )
    ), silent = TRUE)
    }

  ) %>%
  # Add column indicating video number
  map(
    ~ {

      try(mutate(
        .x,
        video_number = as.double(
          str_extract(
            .x$video_name,
            pattern = "[0-9]+"
          )
        )
    ), silent = TRUE)
    }
  ) %>%
  #Catch the errors
  map(~ if (inherits(.x, "try-error")) NULL else .x) %>%
  # # Bind rows to form a single tibble
  bind_rows %>%
  suppressMessages




raw_data_sep <- sep_paths %>% 
  # Read files
  map(
    read_csv, 
    id = "file_name_original",
    col_types = cols()
  ) %>%
  # standardize colnames
  map(standardize_colnames) %>% 
  # Select vars
  map(select_vars) %>% 
  #Add sheep name column
  map(
    ~ {
      try(add_column(
        .x,
        sheep_name = str_extract(
          .x$file_name_original,
          "ov.."
        )
    ), silent = TRUE)
    }
  ) %>% 
  # Add sheep number column
  map(
    ~ try(add_column(
        .x,
        sheep_number = as.double(
          str_extract(
            .x$sheep_name,
            "[0-9]+"
          )
        )
    ), silent = TRUE)
  ) %>%
  # Add Year variable
  map(
    ~ try(mutate(
        .x,
        year = year(DateTime)
    ), silent = TRUE)
  ) %>%
  # Add Month variable
  map(
    ~ try(mutate(
        .x,
        month = month(DateTime)
    ), silent = TRUE)
  ) %>%
  # Add Day variable
  map(
    ~ try(mutate(
        .x,
        day = day(DateTime)
    ), silent = TRUE)
  ) %>%
  
  #Remove DateTime var
  map(
    ~ {
      try(select(
        .x,
        -'DateTime'
    ), silent = TRUE)

    }
  ) %>%
  # Rename all vars to lower-case names to avoid problems
  map(
    ~ {
      try(rename_all(
        .x,
        tolower
    ), silent = TRUE)

    }

  ) %>%
  # Coerce to consistent classes
  map(
    {
    ~ try(mutate_at(
        .x,
        c('hours', 'minutes', 'seconds'),
        as.double
      ), silent = TRUE)

    }
  ) %>%
  # Add column indicating video name
  map(
    ~ {try(mutate(
        .x,
        video_name = str_extract(
          .x$file_name_original,
          pattern = "video.."
        )
    ), silent = TRUE)
    }

  ) %>%
  # Add column indicating video number
  map(
    ~ {

      try(mutate(
        .x,
        video_number = as.double(
          str_extract(
            .x$video_name,
            pattern = "[0-9]+"
          )
        )
    ), silent = TRUE)
    }
  ) %>%
  #Catch the errors
  map(~ if (inherits(.x, "try-error")) NULL else .x) %>%
  # # Bind rows to form a single tibble
  bind_rows %>%
  suppressMessages



```


Now we have the datasets cleaned:

-   September data
```{r}
# reactable(raw_data_sep)


```

-   December data
```{r}

# reactable(raw_data_dic)

```

Now we will merge both datasets, and check which columns contain NAs
```{r}
check_na_percentage <- function(df) {
  nas <- colSums(is.na(df))
  
  return(nas / nrow(df) * 100)
}


check_na_percentage(raw_data_dic)
check_na_percentage(raw_data_sep)




clean_data <- bind_rows(
  raw_data_dic, 
  raw_data_sep
) %>% 
  select(-pitch.smoothed.angle, -roll.smoothed.angle)


check_na_percentage(clean_data)
#  
# 
# print("Amount of NAs in each column")
# nas <- colSums(is.na(clean_data)) %>% print()
# 
# print("Percentage of NAs relative to total rows in dataset")
# nas / nrow(clean_data) * 100 

```




We can see that only the 'behaviours' column contain NAs and they amount to\
about 5% of the entries. (update: also mag_* contain ~1.2% NAs)

We will remove this NAs for the time being, but we will check this again later.\
We will also change the order of the columns and arrange the dataset.
Update: We are no longer dropping NAs, because that will break our 6.4s "mini-time-series"

```{r}

clean_data <- clean_data %>% 
  # # Remove rows containing NAs
  # drop_na %>% # removed this to avoid disrupting the "mini-time-series"
  # Change order of columns
  select(
    'sheep_name', 
    'sheep_number', 
    'year', 
    'month', 
    'day', 
    'hours', 
    'minutes', 
    'seconds',
    'event.no.',
    'acc_x', 
    'acc_y',
    'acc_z', 
    'mag_x', 
    'mag_y',
    'mag_z', 
    'pitch.angle', 
    'roll.angle',
    'behaviours',
    'video_name', 
    'video_number',
    'file_name_original'
  ) %>% 
  # Sort data
  arrange(
    sheep_number, 
    year, 
    month, 
    day, 
    hours, 
    minutes, 
    seconds,
    event.no.
  ) %>% 
  # Rename behaviours with tidyverse style + correct duplicated ones  
  mutate(
    behaviours = recode(
      behaviours, 
      'Search' = 'search', 
      'Eating' = 'eating', 
      'Vigilance' = 'vigilance', 
      'Fast.walk' = 'fast_walk', 
      'Walk' = 'walk', 
      'Fast.Walk' = 'fast_walk', 
      'Scratch' = 'scratch', 
      'Eating.up' = 'eating',
      'Vigilance.down' = 'vigilance', 
      'Resting' = 'resting', 
      'Shake' = 'shake', 
      'Scracth' = 'scratch'
    )
  )
  
```

We will also make a properly created date-time variable for making some plots\
later.

```{r}
clean_data <- clean_data %>% 
  mutate(
    #hours_minutes_seconds = make_datetime(hours, minutes, seconds)
    date_time = make_datetime(year, month, day, hours, minutes, seconds),
    hms = as_hms(date_time)
  )

```


## This data will be stored and then processed in python
```{r}
write_csv(clean_data, here("data", "clean_sheep_data_2019.csv"))


```


